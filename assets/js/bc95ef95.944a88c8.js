"use strict";(self.webpackChunkmy_notes=self.webpackChunkmy_notes||[]).push([[7143],{7852:(e,i,s)=>{s.r(i),s.d(i,{assets:()=>o,contentTitle:()=>l,default:()=>p,frontMatter:()=>a,metadata:()=>n,toc:()=>c});const n=JSON.parse('{"id":"ml/supervised/logistic-regression","title":"Logistic Regression","description":"Understanding Logistic Regression algorithm for binary and multi-class classification","source":"@site/docs/ml/supervised/logistic-regression.md","sourceDirName":"ml/supervised","slug":"/ml/supervised/logistic-regression","permalink":"/my-notes/docs/ml/supervised/logistic-regression","draft":false,"unlisted":false,"editUrl":"https://github.com/nvgr-GenAI/my-notes/edit/main/docs/ml/supervised/logistic-regression.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Logistic Regression","sidebar_position":3,"description":"Understanding Logistic Regression algorithm for binary and multi-class classification"},"sidebar":"mlSidebar","previous":{"title":"Neural Networks for Regression","permalink":"/my-notes/docs/ml/supervised/neural-networks-regression"},"next":{"title":"Decision Tree Classification","permalink":"/my-notes/docs/ml/supervised/decision-tree-classification"}}');var r=s(4848),t=s(8453);const a={title:"Logistic Regression",sidebar_position:3,description:"Understanding Logistic Regression algorithm for binary and multi-class classification"},l="Logistic Regression",o={},c=[{value:"1. Types of Logistic Regression",id:"1-types-of-logistic-regression",level:2},{value:"A. Binary Logistic Regression",id:"a-binary-logistic-regression",level:3},{value:"B. Multinomial Logistic Regression",id:"b-multinomial-logistic-regression",level:3},{value:"C. Ordinal Logistic Regression",id:"c-ordinal-logistic-regression",level:3},{value:"2. How Logistic Regression Works",id:"2-how-logistic-regression-works",level:2},{value:"3. Example Use Case: Email Spam Detection",id:"3-example-use-case-email-spam-detection",level:2},{value:"Scenario",id:"scenario",level:3},{value:"Dataset Sample",id:"dataset-sample",level:3},{value:"Applying Logistic Regression",id:"applying-logistic-regression",level:3},{value:"4. Advantages of Logistic Regression",id:"4-advantages-of-logistic-regression",level:2},{value:"5. Limitations",id:"5-limitations",level:2},{value:"6. Real-World Applications",id:"6-real-world-applications",level:2},{value:"7. Implementation Example",id:"7-implementation-example",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const i={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"logistic-regression",children:"Logistic Regression"})}),"\n",(0,r.jsxs)(i.p,{children:["Logistic Regression is a ",(0,r.jsx)(i.strong,{children:"supervised learning algorithm"})," used for classification problems. Despite its name, it's used for classification, not regression. It predicts the probability of an observation belonging to a certain class."]}),"\n",(0,r.jsx)(i.h2,{id:"1-types-of-logistic-regression",children:"1. Types of Logistic Regression"}),"\n",(0,r.jsx)(i.h3,{id:"a-binary-logistic-regression",children:"A. Binary Logistic Regression"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Used when the dependent variable has only two possible outcomes (Yes/No, 0/1)"}),"\n",(0,r.jsx)(i.li,{children:"Examples: Email spam detection (Spam/Not Spam), Disease diagnosis (Present/Absent)"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"b-multinomial-logistic-regression",children:"B. Multinomial Logistic Regression"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Used when the dependent variable has three or more unordered categories"}),"\n",(0,r.jsx)(i.li,{children:"Example: Predicting the type of cuisine (Italian, Chinese, Mexican, etc.)"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"c-ordinal-logistic-regression",children:"C. Ordinal Logistic Regression"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Used when the dependent variable has three or more ordered categories"}),"\n",(0,r.jsx)(i.li,{children:"Example: Movie ratings (1 star, 2 stars, 3 stars, etc.)"}),"\n"]}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"2-how-logistic-regression-works",children:"2. How Logistic Regression Works"}),"\n",(0,r.jsxs)(i.p,{children:["Logistic Regression uses the ",(0,r.jsx)(i.strong,{children:"logistic (sigmoid) function"})," to transform a linear prediction into a probability between 0 and 1:"]}),"\n",(0,r.jsx)(i.p,{children:"P(Y=1) = 1 / (1 + e^(-z))"}),"\n",(0,r.jsx)(i.p,{children:"Where:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"P(Y=1) is the probability that the observation belongs to class 1"}),"\n",(0,r.jsx)(i.li,{children:"z is the linear combination of features: z = b\u2080 + b\u2081X\u2081 + b\u2082X\u2082 + ... + b\u2099X\u2099"}),"\n",(0,r.jsx)(i.li,{children:"e is the base of natural logarithm (approximately 2.71828)"}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"The decision boundary is:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"If P(Y=1) \u2265 0.5, predict class 1"}),"\n",(0,r.jsx)(i.li,{children:"If P(Y=1) < 0.5, predict class 0"}),"\n"]}),"\n",(0,r.jsxs)(i.p,{children:["The model is trained using ",(0,r.jsx)(i.strong,{children:"Maximum Likelihood Estimation"}),", which finds the parameters that maximize the likelihood of observing the given data."]}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"3-example-use-case-email-spam-detection",children:"3. Example Use Case: Email Spam Detection"}),"\n",(0,r.jsx)(i.h3,{id:"scenario",children:"Scenario"}),"\n",(0,r.jsx)(i.p,{children:"An email service wants to classify incoming emails as spam or not spam based on features like:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"Number of uppercase words"}),"\n",(0,r.jsx)(i.li,{children:"Number of suspicious phrases"}),"\n",(0,r.jsx)(i.li,{children:"Presence of URL with different domain than sender"}),"\n",(0,r.jsx)(i.li,{children:"Email length"}),"\n"]}),"\n",(0,r.jsx)(i.h3,{id:"dataset-sample",children:"Dataset Sample"}),"\n",(0,r.jsxs)(i.table,{children:[(0,r.jsx)(i.thead,{children:(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.th,{children:"Uppercase Words"}),(0,r.jsx)(i.th,{children:"Suspicious Phrases"}),(0,r.jsx)(i.th,{children:"Different Domain URL"}),(0,r.jsx)(i.th,{children:"Length (words)"}),(0,r.jsx)(i.th,{children:"Is Spam"})]})}),(0,r.jsxs)(i.tbody,{children:[(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"10"}),(0,r.jsx)(i.td,{children:"5"}),(0,r.jsx)(i.td,{children:"Yes"}),(0,r.jsx)(i.td,{children:"150"}),(0,r.jsx)(i.td,{children:"Yes"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"2"}),(0,r.jsx)(i.td,{children:"0"}),(0,r.jsx)(i.td,{children:"No"}),(0,r.jsx)(i.td,{children:"200"}),(0,r.jsx)(i.td,{children:"No"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"15"}),(0,r.jsx)(i.td,{children:"8"}),(0,r.jsx)(i.td,{children:"Yes"}),(0,r.jsx)(i.td,{children:"50"}),(0,r.jsx)(i.td,{children:"Yes"})]}),(0,r.jsxs)(i.tr,{children:[(0,r.jsx)(i.td,{children:"3"}),(0,r.jsx)(i.td,{children:"1"}),(0,r.jsx)(i.td,{children:"No"}),(0,r.jsx)(i.td,{children:"180"}),(0,r.jsx)(i.td,{children:"No"})]})]})]}),"\n",(0,r.jsx)(i.h3,{id:"applying-logistic-regression",children:"Applying Logistic Regression"}),"\n",(0,r.jsx)(i.p,{children:"The model learns the relationship:"}),"\n",(0,r.jsx)(i.p,{children:"P(Spam) = 1 / (1 + e^-(b\u2080 + b\u2081(Uppercase) + b\u2082(Suspicious) + b\u2083(URL) + b\u2084(Length)))"}),"\n",(0,r.jsx)(i.p,{children:"If the trained model gives coefficients:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"b\u2080 = -5.0 (intercept)"}),"\n",(0,r.jsx)(i.li,{children:"b\u2081 = 0.4 (Uppercase Words)"}),"\n",(0,r.jsx)(i.li,{children:"b\u2082 = 0.8 (Suspicious Phrases)"}),"\n",(0,r.jsx)(i.li,{children:"b\u2083 = 2.5 (Different Domain URL, where 1=Yes, 0=No)"}),"\n",(0,r.jsx)(i.li,{children:"b\u2084 = -0.01 (Length)"}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"For a new email with:"}),"\n",(0,r.jsxs)(i.ul,{children:["\n",(0,r.jsx)(i.li,{children:"12 uppercase words"}),"\n",(0,r.jsx)(i.li,{children:"6 suspicious phrases"}),"\n",(0,r.jsx)(i.li,{children:"Contains a different domain URL (1)"}),"\n",(0,r.jsx)(i.li,{children:"100 words length"}),"\n"]}),"\n",(0,r.jsx)(i.p,{children:"z = -5.0 + 0.4(12) + 0.8(6) + 2.5(1) + (-0.01)(100)\nz = -5.0 + 4.8 + 4.8 + 2.5 - 1.0 = 6.1"}),"\n",(0,r.jsx)(i.p,{children:"P(Spam) = 1 / (1 + e^(-6.1)) \u2248 0.998"}),"\n",(0,r.jsx)(i.p,{children:"With a probability of 0.998, the email would be classified as spam."}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"4-advantages-of-logistic-regression",children:"4. Advantages of Logistic Regression"}),"\n",(0,r.jsx)(i.p,{children:"\u2705 Provides probabilities rather than just classifications"}),"\n",(0,r.jsx)(i.p,{children:"\u2705 Efficient to train and doesn't require high computational power"}),"\n",(0,r.jsx)(i.p,{children:"\u2705 Less prone to overfitting when regularization is used"}),"\n",(0,r.jsx)(i.p,{children:"\u2705 Highly interpretable - coefficients directly indicate feature importance and direction"}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"5-limitations",children:"5. Limitations"}),"\n",(0,r.jsx)(i.p,{children:"\u274c Assumes linearity between independent variables and the log-odds of the outcome"}),"\n",(0,r.jsx)(i.p,{children:"\u274c May underperform when there are complex relationships between variables"}),"\n",(0,r.jsx)(i.p,{children:"\u274c Requires more data to achieve stability when there are many features"}),"\n",(0,r.jsx)(i.p,{children:"\u274c Struggles with imbalanced datasets without proper adjustments"}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"6-real-world-applications",children:"6. Real-World Applications"}),"\n",(0,r.jsxs)(i.p,{children:["\ud83d\udce7 ",(0,r.jsx)(i.strong,{children:"Email Spam Detection"})," \u2013 Classifying emails as spam or legitimate"]}),"\n",(0,r.jsxs)(i.p,{children:["\ud83c\udfe5 ",(0,r.jsx)(i.strong,{children:"Disease Diagnosis"})," \u2013 Predicting the presence of a disease based on symptoms and test results"]}),"\n",(0,r.jsxs)(i.p,{children:["\ud83d\udcb3 ",(0,r.jsx)(i.strong,{children:"Credit Card Fraud Detection"})," \u2013 Identifying fraudulent transactions"]}),"\n",(0,r.jsxs)(i.p,{children:["\ud83d\udcf1 ",(0,r.jsx)(i.strong,{children:"Customer Churn Prediction"})," \u2013 Determining which customers are likely to leave a service"]}),"\n",(0,r.jsxs)(i.p,{children:["\ud83d\uddf3\ufe0f ",(0,r.jsx)(i.strong,{children:"Voter Behavior Prediction"})," \u2013 Forecasting whether someone will vote for a particular candidate"]}),"\n",(0,r.jsx)(i.hr,{}),"\n",(0,r.jsx)(i.h2,{id:"7-implementation-example",children:"7. Implementation Example"}),"\n",(0,r.jsx)(i.pre,{children:(0,r.jsx)(i.code,{className:"language-python",children:'# Install Dependencies\n# pip install numpy pandas scikit-learn matplotlib seaborn\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n\n# Sample email spam dataset\ndata = {\n    "Uppercase_Words": [10, 2, 15, 3, 20, 5, 12, 1, 8, 2, 18, 4, 7, 3, 9],\n    "Suspicious_Phrases": [5, 0, 8, 1, 10, 2, 6, 0, 4, 1, 9, 0, 3, 1, 5],\n    "Different_Domain_URL": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0],  # 1=Yes, 0=No\n    "Length": [150, 200, 50, 180, 100, 220, 90, 300, 120, 250, 80, 270, 180, 200, 150],\n    "Is_Spam": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]  # 1=Spam, 0=Not Spam\n}\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\n\n# Display the first few rows\nprint(df.head())\n\n# Visualize correlations\nplt.figure(figsize=(10, 8))\nsns.heatmap(df.corr(), annot=True, cmap=\'coolwarm\')\nplt.title("Feature Correlations")\nplt.show()\n\n# Prepare the data\nX = df[["Uppercase_Words", "Suspicious_Phrases", "Different_Domain_URL", "Length"]]\ny = df["Is_Spam"]\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Standardize features (important for logistic regression)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Create and train the model with regularization\nmodel = LogisticRegression(C=1.0, penalty=\'l2\', solver=\'liblinear\')\nmodel.fit(X_train_scaled, y_train)\n\n# Print model coefficients\nprint("Intercept:", model.intercept_[0])\nprint("Coefficients:")\nfor feature, coef in zip(X.columns, model.coef_[0]):\n    print(f"{feature}: {coef}")\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\ny_prob = model.predict_proba(X_test_scaled)[:, 1]  # Probability of being spam\n\n# Evaluate the model\nprint("\\nAccuracy:", accuracy_score(y_test, y_pred))\n\nprint("\\nConfusion Matrix:")\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt=\'d\', cmap=\'Blues\', xticklabels=[\'Not Spam\', \'Spam\'], yticklabels=[\'Not Spam\', \'Spam\'])\nplt.xlabel(\'Predicted\')\nplt.ylabel(\'Actual\')\nplt.show()\n\nprint("\\nClassification Report:")\nprint(classification_report(y_test, y_pred, target_names=[\'Not Spam\', \'Spam\']))\n\n# Plot ROC curve\nfpr, tpr, thresholds = roc_curve(y_test, y_prob)\nauc = roc_auc_score(y_test, y_prob)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, label=f\'ROC curve (area = {auc:.2f})\')\nplt.plot([0, 1], [0, 1], \'k--\')  # Random prediction line\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel(\'False Positive Rate\')\nplt.ylabel(\'True Positive Rate\')\nplt.title(\'Receiver Operating Characteristic (ROC) Curve\')\nplt.legend(loc="lower right")\nplt.show()\n\n# Make a prediction for a new email\nnew_email = np.array([[12, 6, 1, 100]])  # 12 uppercase words, 6 suspicious phrases, has different domain URL, 100 words long\nnew_email_scaled = scaler.transform(new_email)\nspam_probability = model.predict_proba(new_email_scaled)[0, 1]\n\nprint(f"\\nPrediction for new email:")\nprint(f"Spam probability: {spam_probability:.4f}")\nprint(f"Classification: {\'Spam\' if spam_probability >= 0.5 else \'Not Spam\'}")\n'})}),"\n",(0,r.jsx)(i.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(i.p,{children:"\u2705 Built a Logistic Regression model for email spam detection"}),"\n",(0,r.jsx)(i.p,{children:"\u2705 Learned how the model uses the sigmoid function to predict probabilities"}),"\n",(0,r.jsx)(i.p,{children:"\u2705 Demonstrated coefficients interpretation for feature importance"}),"\n",(0,r.jsx)(i.p,{children:"\u2705 Evaluated the model using accuracy, confusion matrix, and ROC curve"}),"\n",(0,r.jsx)(i.p,{children:"\u2705 Applied the model to classify new emails as spam or not spam"})]})}function p(e={}){const{wrapper:i}={...(0,t.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,i,s)=>{s.d(i,{R:()=>a,x:()=>l});var n=s(6540);const r={},t=n.createContext(r);function a(e){const i=n.useContext(t);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function l(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),n.createElement(t.Provider,{value:i},e.children)}}}]);