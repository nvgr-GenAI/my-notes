"use strict";(self.webpackChunkmy_notes=self.webpackChunkmy_notes||[]).push([[64],{7147:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>p,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"ml/supervised/support-vector-machines","title":"Support Vector Machines","description":"Understanding Support Vector Machine algorithms for classification and regression","source":"@site/docs/ml/supervised/support-vector-machines.md","sourceDirName":"ml/supervised","slug":"/ml/supervised/support-vector-machines","permalink":"/my-notes/docs/ml/supervised/support-vector-machines","draft":false,"unlisted":false,"editUrl":"https://github.com/nvgr-GenAI/my-notes/edit/main/docs/ml/supervised/support-vector-machines.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"title":"Support Vector Machines","sidebar_position":6,"description":"Understanding Support Vector Machine algorithms for classification and regression"}}');var r=i(4848),t=i(8453);const a={title:"Support Vector Machines",sidebar_position:6,description:"Understanding Support Vector Machine algorithms for classification and regression"},o="Support Vector Machines (SVM)",l={},c=[{value:"1. Types of Support Vector Machines",id:"1-types-of-support-vector-machines",level:2},{value:"A. Support Vector Classification (SVC)",id:"a-support-vector-classification-svc",level:3},{value:"B. Support Vector Regression (SVR)",id:"b-support-vector-regression-svr",level:3},{value:"2. How Support Vector Machines Work",id:"2-how-support-vector-machines-work",level:2},{value:"Core Concepts:",id:"core-concepts",level:3},{value:"Mathematical Foundation:",id:"mathematical-foundation",level:3},{value:"3. Example Use Case: Face Recognition",id:"3-example-use-case-face-recognition",level:2},{value:"Scenario",id:"scenario",level:3},{value:"Dataset Sample",id:"dataset-sample",level:3},{value:"SVM Approach",id:"svm-approach",level:3},{value:"4. Advantages of SVM",id:"4-advantages-of-svm",level:2},{value:"5. Limitations",id:"5-limitations",level:2},{value:"6. Real-World Applications",id:"6-real-world-applications",level:2},{value:"7. Implementation Example",id:"7-implementation-example",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"support-vector-machines-svm",children:"Support Vector Machines (SVM)"})}),"\n",(0,r.jsxs)(n.p,{children:["Support Vector Machines (SVM) are powerful ",(0,r.jsx)(n.strong,{children:"supervised learning algorithms"})," used primarily for classification but also applicable to regression. They work by finding the optimal hyperplane that best separates data points of different classes with the maximum margin of separation."]}),"\n",(0,r.jsx)(n.h2,{id:"1-types-of-support-vector-machines",children:"1. Types of Support Vector Machines"}),"\n",(0,r.jsx)(n.h3,{id:"a-support-vector-classification-svc",children:"A. Support Vector Classification (SVC)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Linear SVC: Uses a linear kernel for linearly separable data"}),"\n",(0,r.jsx)(n.li,{children:"Non-linear SVC: Uses non-linear kernels (RBF, polynomial, sigmoid) for complex data"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"b-support-vector-regression-svr",children:"B. Support Vector Regression (SVR)"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Predicts continuous values while maintaining the core principles of SVM"}),"\n",(0,r.jsx)(n.li,{children:"Uses an epsilon-insensitive loss function that ignores errors within a certain distance"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"2-how-support-vector-machines-work",children:"2. How Support Vector Machines Work"}),"\n",(0,r.jsx)(n.h3,{id:"core-concepts",children:"Core Concepts:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Hyperplane"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"In 2D, it's a line; in 3D, a plane; and in higher dimensions, a hyperplane"}),"\n",(0,r.jsx)(n.li,{children:"Separates data points of different classes"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Margin"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Distance between the hyperplane and the nearest data points (support vectors)"}),"\n",(0,r.jsx)(n.li,{children:"SVM aims to maximize this margin"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Support Vectors"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Data points closest to the decision boundary"}),"\n",(0,r.jsx)(n.li,{children:"Critical for defining the hyperplane"}),"\n",(0,r.jsx)(n.li,{children:"Only these points affect the position of the hyperplane"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Kernel Trick"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Transforms data into higher dimensions where it becomes linearly separable"}),"\n",(0,r.jsx)(n.li,{children:"Common kernels: Linear, Polynomial, Radial Basis Function (RBF), Sigmoid"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"mathematical-foundation",children:"Mathematical Foundation:"}),"\n",(0,r.jsx)(n.p,{children:"SVM optimizes this objective function:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Minimize: \xbd||w||\xb2 + C\u2211\u03be\u1d62"}),"\n",(0,r.jsx)(n.li,{children:"Subject to: y\u1d62(w\xb7x\u1d62 + b) \u2265 1 - \u03be\u1d62 and \u03be\u1d62 \u2265 0 for all i"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"Where:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"w = weight vector"}),"\n",(0,r.jsx)(n.li,{children:"b = bias"}),"\n",(0,r.jsx)(n.li,{children:"C = regularization parameter"}),"\n",(0,r.jsx)(n.li,{children:"\u03be\u1d62 = slack variables (allowing some misclassification)"}),"\n",(0,r.jsx)(n.li,{children:"(x\u1d62, y\u1d62) = training examples and labels"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"3-example-use-case-face-recognition",children:"3. Example Use Case: Face Recognition"}),"\n",(0,r.jsx)(n.h3,{id:"scenario",children:"Scenario"}),"\n",(0,r.jsx)(n.p,{children:"A security system wants to automatically identify authorized personnel using facial features. It extracts various facial measurements and uses SVM to classify whether a person is authorized or unauthorized."}),"\n",(0,r.jsx)(n.h3,{id:"dataset-sample",children:"Dataset Sample"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Eye Distance"}),(0,r.jsx)(n.th,{children:"Nose Length"}),(0,r.jsx)(n.th,{children:"Face Width"}),(0,r.jsx)(n.th,{children:"Jaw Angle"}),(0,r.jsx)(n.th,{children:"Authorized"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6.2"}),(0,r.jsx)(n.td,{children:"5.1"}),(0,r.jsx)(n.td,{children:"14.3"}),(0,r.jsx)(n.td,{children:"92\xb0"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5.8"}),(0,r.jsx)(n.td,{children:"4.8"}),(0,r.jsx)(n.td,{children:"13.9"}),(0,r.jsx)(n.td,{children:"89\xb0"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6.5"}),(0,r.jsx)(n.td,{children:"5.3"}),(0,r.jsx)(n.td,{children:"15.0"}),(0,r.jsx)(n.td,{children:"95\xb0"}),(0,r.jsx)(n.td,{children:"No"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"5.9"}),(0,r.jsx)(n.td,{children:"4.9"}),(0,r.jsx)(n.td,{children:"13.8"}),(0,r.jsx)(n.td,{children:"91\xb0"}),(0,r.jsx)(n.td,{children:"Yes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"6.4"}),(0,r.jsx)(n.td,{children:"5.4"}),(0,r.jsx)(n.td,{children:"14.8"}),(0,r.jsx)(n.td,{children:"94\xb0"}),(0,r.jsx)(n.td,{children:"No"})]})]})]}),"\n",(0,r.jsx)(n.h3,{id:"svm-approach",children:"SVM Approach"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data Preprocessing"}),": Normalize facial measurements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Kernel Selection"}),": Use RBF kernel for non-linear decision boundary"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hyperparameter Tuning"}),": Optimize C (regularization) and gamma (kernel coefficient)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Training"}),": SVM learns the optimal hyperplane"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Classification"}),": New faces are classified based on which side of the hyperplane they fall on"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"For a new face with measurements:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Eye Distance: 6.1"}),"\n",(0,r.jsx)(n.li,{children:"Nose Length: 5.0"}),"\n",(0,r.jsx)(n.li,{children:"Face Width: 14.2"}),"\n",(0,r.jsx)(n.li,{children:"Jaw Angle: 90\xb0"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"The SVM calculates its position relative to the hyperplane and outputs a classification (Authorized/Unauthorized) and confidence score."}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"4-advantages-of-svm",children:"4. Advantages of SVM"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Effective in high-dimensional spaces, even when dimensions exceed samples"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Memory efficient, using only a subset of training points (support vectors)"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Versatile through different kernel functions for various decision boundaries"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Robust against overfitting, especially in high-dimensional spaces"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Finds the global minimum, avoiding local minima problems"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"5-limitations",children:"5. Limitations"}),"\n",(0,r.jsx)(n.p,{children:"\u274c Not well-suited for very large datasets due to quadratic training time complexity"}),"\n",(0,r.jsx)(n.p,{children:"\u274c Performance degrades with noisy data and overlapping classes"}),"\n",(0,r.jsx)(n.p,{children:"\u274c Requires careful tuning of hyperparameters (C, gamma, kernel)"}),"\n",(0,r.jsx)(n.p,{children:"\u274c Doesn't directly provide probability estimates (requires additional calibration)"}),"\n",(0,r.jsx)(n.p,{children:"\u274c Challenging to interpret compared to simpler models"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"6-real-world-applications",children:"6. Real-World Applications"}),"\n",(0,r.jsxs)(n.p,{children:["\ud83d\udc64 ",(0,r.jsx)(n.strong,{children:"Face Recognition"})," \u2013 Identifying individuals from facial features"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83d\udcc4 ",(0,r.jsx)(n.strong,{children:"Text Classification"})," \u2013 Categorizing documents by topic or sentiment"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83e\uddec ",(0,r.jsx)(n.strong,{children:"Bioinformatics"})," \u2013 Protein classification and gene expression analysis"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83d\uddbc\ufe0f ",(0,r.jsx)(n.strong,{children:"Image Classification"})," \u2013 Detecting objects or patterns in images"]}),"\n",(0,r.jsxs)(n.p,{children:["\ud83e\ude7a ",(0,r.jsx)(n.strong,{children:"Medical Diagnosis"})," \u2013 Classifying medical conditions based on test results"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"7-implementation-example",children:"7. Implementation Example"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Install Dependencies\n# pip install numpy pandas scikit-learn matplotlib seaborn\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom sklearn.decomposition import PCA  # For visualization\n\n# Sample face recognition dataset\ndata = {\n    "EyeDistance": [6.2, 5.8, 6.5, 5.9, 6.4, 6.1, 5.7, 6.3, 6.0, 6.6, 5.9, 6.2, 6.4, 5.8, 6.3, 6.0, 5.9, 6.5, 6.1, 6.2],\n    "NoseLength": [5.1, 4.8, 5.3, 4.9, 5.4, 5.0, 4.7, 5.2, 4.9, 5.5, 4.8, 5.1, 5.3, 4.7, 5.2, 5.0, 4.9, 5.4, 5.1, 5.2],\n    "FaceWidth": [14.3, 13.9, 15.0, 13.8, 14.8, 14.1, 13.7, 14.5, 14.0, 15.2, 13.9, 14.2, 14.7, 13.8, 14.6, 14.1, 13.9, 15.1, 14.2, 14.4],\n    "JawAngle": [92, 89, 95, 91, 94, 90, 88, 93, 92, 96, 90, 91, 94, 89, 93, 91, 90, 95, 92, 93],\n    "Authorized": ["Yes", "Yes", "No", "Yes", "No", "Yes", "Yes", "No", "Yes", "No", \n                   "Yes", "Yes", "No", "Yes", "No", "Yes", "Yes", "No", "Yes", "No"]\n}\n\n# Convert to DataFrame\ndf = pd.DataFrame(data)\n\n# Encode the target variable\ndf["Authorized_Encoded"] = df["Authorized"].map({"Yes": 1, "No": 0})\n\n# Display the first few rows\nprint(df.head())\n\n# Visualize data relationships\nplt.figure(figsize=(12, 10))\nsns.pairplot(df, hue="Authorized", vars=["EyeDistance", "NoseLength", "FaceWidth", "JawAngle"])\nplt.suptitle("Facial Feature Relationships by Authorization Status", y=1.02)\nplt.show()\n\n# Prepare the data\nX = df[["EyeDistance", "NoseLength", "FaceWidth", "JawAngle"]]\ny = df["Authorized_Encoded"]\n\n# Standardize features (important for SVM)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n\n# Create and train the SVM model\n# Use Grid Search to find optimal hyperparameters\nparam_grid = {\n    \'C\': [0.1, 1, 10, 100],\n    \'gamma\': [\'scale\', \'auto\', 0.1, 0.01],\n    \'kernel\': [\'rbf\', \'poly\', \'sigmoid\']\n}\n\ngrid_search = GridSearchCV(SVC(probability=True), param_grid, cv=5, scoring=\'accuracy\', verbose=1)\ngrid_search.fit(X_train, y_train)\n\nprint(f"Best parameters: {grid_search.best_params_}")\nprint(f"Best cross-validation score: {grid_search.best_score_:.4f}")\n\n# Get the best model\nbest_model = grid_search.best_estimator_\n\n# Make predictions\ny_pred = best_model.predict(X_test)\ny_prob = best_model.predict_proba(X_test)[:, 1]  # Probability of being authorized\n\n# Evaluate the model\nprint("\\nAccuracy:", accuracy_score(y_test, y_pred))\n\nprint("\\nConfusion Matrix:")\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt=\'d\', cmap=\'Blues\', xticklabels=[\'Unauthorized\', \'Authorized\'], yticklabels=[\'Unauthorized\', \'Authorized\'])\nplt.xlabel(\'Predicted\')\nplt.ylabel(\'Actual\')\nplt.show()\n\nprint("\\nClassification Report:")\nprint(classification_report(y_test, y_pred, target_names=[\'Unauthorized\', \'Authorized\']))\n\n# Visualize decision boundaries (using PCA for dimensionality reduction to 2D)\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Train SVM on the PCA-transformed data\nsvm_pca = SVC(kernel=\'rbf\', C=best_model.C, gamma=best_model.gamma, probability=True)\nsvm_pca.fit(pca.transform(X_train), y_train)\n\n# Create a mesh grid for plotting the decision boundary\nh = 0.02  # step size in the mesh\nx_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\ny_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\nZ = svm_pca.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\n# Plot the decision boundary and data points\nplt.figure(figsize=(10, 8))\nplt.contourf(xx, yy, Z, alpha=0.8, cmap=plt.cm.coolwarm)\nplt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, edgecolors=\'k\', cmap=plt.cm.coolwarm)\nplt.xlabel(\'Principal Component 1\')\nplt.ylabel(\'Principal Component 2\')\nplt.title(\'SVM Decision Boundary (with PCA for visualization)\')\nplt.show()\n\n# Make a prediction for a new face\nnew_face = np.array([[6.1, 5.0, 14.2, 90]])  # Eye Distance, Nose Length, Face Width, Jaw Angle\nnew_face_scaled = scaler.transform(new_face)\nprediction = best_model.predict(new_face_scaled)\nprobability = best_model.predict_proba(new_face_scaled)\n\nprint(f"\\nPrediction for new face:")\nprint(f"Decision: {\'Authorized\' if prediction[0] == 1 else \'Unauthorized\'}")\nprint(f"Authorization Probability: {probability[0][1]:.4f}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Built an SVM model for face recognition classification"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Learned how SVM finds the optimal hyperplane with maximum margin"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Used grid search to find the best hyperparameters"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Visualized the decision boundary in a reduced dimension space"}),"\n",(0,r.jsx)(n.p,{children:"\u2705 Evaluated model performance and made predictions for new faces"})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var s=i(6540);const r={},t=s.createContext(r);function a(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);